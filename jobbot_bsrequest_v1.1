#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Fri Aug 30 14:21:55 2019

@author: Tarik
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import os

#Demander le(s) mot(s) clés & et le(s) lieu(x)
query = input("Veuillez enter le(s) mot(s) clés pour la recherche: \n").lower()
location = input("Veuillez enter le(s) lieu(x) pour la recherche: \n").upper()


#launch url
url = 'https://candidat.pole-emploi.fr/offres/recherche?lieux={}&motsCles={}&offresPartenaires=true&range=0-9&rayon=10&tri=0'.format(location,query)
base_url="https://candidat.pole-emploi.fr"

#Critères : données + centre val de loire
req = requests.get(url)
soup = BeautifulSoup(req.text, "lxml")

#Nombre d'offres
titre = soup.find('h1', class_ ='title')
nb_offres = int(titre.next_element.replace('\n', '').replace(' offres', ''))



if (nb_offres>150):
    nbpage= (nb_offres//150)+1
    url2=150
else:
    url2=nb_offres
    nbpage=1
url1=0

#Creation de liste

title=[]
Publication=[]
Experiences=[]
Localisation=[]

listeallUrl=[]
for i in range(nbpage):
    
    print("------------",i,"---------") 
    
    url='https://candidat.pole-emploi.fr/offres/recherche?lieux={}&motsCles={}&offresPartenaires=true&range='.format(location,query) +str(url1)+'-'+str(url2)+'&rayon=10&tri=0'
    uc=nb_offres-url2
    
    if (uc>150):
        url1+=150
        if (url1==url2):
            url1+=1
        url2+=150
    else:
        url1=url2
        url2=nb_offres
        
    req = requests.get(url)
    soup = BeautifulSoup(req.text, "lxml")
    
    for liens in soup.find_all('h2', class_ ='t4 media-heading'):
        allUrl=(liens.find('a', class_ ='btn-reset')['href'])
        listeallUrl.append(base_url+allUrl)
        offreUrl=base_url+allUrl
        print(base_url+allUrl)
        
        
            
        requete=requests.get(offreUrl)
        soup[i] = BeautifulSoup(requete.text, "lxml")
        #print(soup[i])
        #try:
        #Ajout Titre des annonces
        for titre in soup[i].find_all('h1', {'itemprop' : 'title'}):
            Titre=titre.text.replace('\n', '')
            print(Titre)
            title.append(Titre)
        

        
        for date in soup[i].find_all('span', {'itemprop' : 'datePosted'}):
            Date=date.next_element.replace('\n', '')
            print(Date)
            Publication.append(Date)
            
        for experience in soup[i].find_all('span', {'itemprop' : 'experienceRequirements'}):
            exp=experience.next_element.replace('\n', '')
            print(exp)
            Experiences.append(exp)
        
        for city in soup[i].find_all('span', {'itemprop' : 'name'}):
        
            Ville=[]
            Ville=[city].pop(0)
            
            print(Ville)
            Localisation.append(Ville)        
        

    
        

    


    








#
#for date in soup.find_all('p', {'class' : 'date'}):
#    Date=date.text.replace('\n', '')
#    print(Date)
#    Publication.append(Date)
#
#for desc in soup.find_all('p', {'class' : 'description'}):
#    print(desc.text.replace('\n', ''))


 
